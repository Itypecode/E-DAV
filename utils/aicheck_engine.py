# utils/aicheck_engine.py
import os
import instructor
from dotenv import load_dotenv
from pydantic import BaseModel
from groq import Groq

load_dotenv()   

keys = os.getenv("GROQ_API_KEY")
client = instructor.from_groq(
    Groq(api_key = keys),
    mode=instructor.Mode.JSON)

async def detect_ai_content(text: str) -> dict:
    prompt = f"""
You are an academic integrity analysis system.

Analyze the following student response and estimate the likelihood that it was generated by an AI system.

Return STRICT JSON ONLY:
{{
  "ai_score": number (0-100),
  "confidence": "LOW" | "MEDIUM" | "HIGH",
  "reason": "short technical justification"
}}

Scoring rules:
- 0 = confidently human-written
- 100 = confidently AI-generated
- Confidence must reflect statistical certainty, not stylistic strength
- If both AI-like and human-like statistical signals are present, the ai_score must remain below 50 unless optimization patterns clearly dominate.

Mandatory evaluation criteria:
- Assess entropy and predictability RELATIVE TO TASK CONSTRAINTS (e.g., exam answers, definitions).
- Distinguish lexical repetition from syntactic or structural repetition.
- Measure local entropy variance across sentences and bullets.
- High predictability of domain-specific technical terms alone MUST NOT increase ai_score.
- Identify unresolved redundancy, error loops, or imperfect repetition as human signals.
- Penalize conclusions based solely on low entropy in technical or academic contexts.

Restrictions:
- Do NOT judge meaning, correctness, or clarity.
- Do NOT assume low entropy implies AI without normalization.
- The reason MUST reference at least one of:
  predictability, entropy variance, structural repetition, or optimization pressure.

Text:
\"\"\"{text}\"\"\"
"""
    class UserInfo(BaseModel):
        ai_score: int
        confidence: str
        reason: str
    try:
        response = client.chat.completions.create(
        model="llama-3.3-70b-versatile",
        response_model=UserInfo,
        messages=[
        {"role": "user", "content": prompt}
        ],
        temperature = 0.5,
        max_retries = 0
        )
        if not response:
            return {"ai_score": 0, "confidence": None, "reason": "No response"}

        return dict(response)

    except Exception as e:
        print("[AI DETECTION ERROR]", e)
        return {"ai_score": 0, "confidence": None, "reason": "Detection failed"}
